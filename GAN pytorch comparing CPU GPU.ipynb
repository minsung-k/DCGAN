{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image\n",
    "import pandas as pd\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "0\n",
      "1\n",
      "Quadro P1000\n"
     ]
    }
   ],
   "source": [
    "print(torch.cuda.is_available())\n",
    "print(torch.cuda.current_device())\n",
    "print(torch.cuda.device_count())\n",
    "print(torch.cuda.get_device_name(0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device configuration\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Hyper-parameters\n",
    "latent_size = 64\n",
    "hidden_size = 256\n",
    "image_size = 784\n",
    "num_epochs = 200\n",
    "batch_size = 100\n",
    "sample_dir = 'samples'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a directory if not exists\n",
    "if not os.path.exists(sample_dir):\n",
    "    os.makedirs(sample_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "                transforms.ToTensor(),\n",
    "                transforms.Normalize(mean=[0.5],   # 1 for greyscale channels\n",
    "                                     std=[0.5])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MNIST dataset\n",
    "mnist = torchvision.datasets.MNIST(root='../../data/',\n",
    "                                   train=True,\n",
    "                                   transform=transform,\n",
    "                                   download=True)\n",
    "\n",
    "# Data loader\n",
    "data_loader = torch.utils.data.DataLoader(dataset=mnist,\n",
    "                                          batch_size=batch_size, \n",
    "                                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Discriminator\n",
    "D = nn.Sequential(\n",
    "    nn.Linear(image_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.LeakyReLU(0.2),\n",
    "    nn.Linear(hidden_size, 1),\n",
    "    nn.Sigmoid())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generator \n",
    "G = nn.Sequential(\n",
    "    nn.Linear(latent_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, hidden_size),\n",
    "    nn.ReLU(),\n",
    "    nn.Linear(hidden_size, image_size),\n",
    "    nn.Tanh())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# ================================================================== #\n",
      "#                                      cpu                                         #\n",
      "# ================================================================== #\n",
      "Epoch [0/200], Step [200/600], d_loss: 0.4160, g_loss: 5.4803, D(x): 0.86, D(G(z)): 0.02\n",
      "Epoch [0/200], Step [400/600], d_loss: 0.0908, g_loss: 6.8134, D(x): 0.96, D(G(z)): 0.02\n",
      "Epoch [0/200], Step [600/600], d_loss: 0.0927, g_loss: 6.3092, D(x): 0.97, D(G(z)): 0.03\n",
      "cpu Computing Time: 26.5900\n",
      "Epoch [25/200], Step [200/600], d_loss: 0.2319, g_loss: 3.8343, D(x): 0.91, D(G(z)): 0.06\n",
      "Epoch [25/200], Step [400/600], d_loss: 0.5225, g_loss: 3.0529, D(x): 0.79, D(G(z)): 0.07\n",
      "Epoch [25/200], Step [600/600], d_loss: 0.6297, g_loss: 3.1705, D(x): 0.82, D(G(z)): 0.13\n",
      "Epoch [50/200], Step [200/600], d_loss: 0.7602, g_loss: 2.4219, D(x): 0.72, D(G(z)): 0.14\n",
      "Epoch [50/200], Step [400/600], d_loss: 0.4936, g_loss: 1.5299, D(x): 0.88, D(G(z)): 0.23\n",
      "Epoch [50/200], Step [600/600], d_loss: 0.7271, g_loss: 2.4265, D(x): 0.78, D(G(z)): 0.22\n",
      "cpu Computing Time: 1548.7300\n",
      "Epoch [75/200], Step [200/600], d_loss: 0.7578, g_loss: 2.6193, D(x): 0.73, D(G(z)): 0.19\n",
      "Epoch [75/200], Step [400/600], d_loss: 0.9796, g_loss: 1.8819, D(x): 0.70, D(G(z)): 0.27\n",
      "Epoch [75/200], Step [600/600], d_loss: 0.8891, g_loss: 1.9048, D(x): 0.79, D(G(z)): 0.37\n",
      "Epoch [100/200], Step [200/600], d_loss: 0.6881, g_loss: 2.4436, D(x): 0.69, D(G(z)): 0.13\n",
      "Epoch [100/200], Step [400/600], d_loss: 0.9245, g_loss: 1.6974, D(x): 0.78, D(G(z)): 0.38\n",
      "Epoch [100/200], Step [600/600], d_loss: 0.9229, g_loss: 1.7857, D(x): 0.66, D(G(z)): 0.23\n",
      "cpu Computing Time: 3078.5677\n",
      "Epoch [125/200], Step [200/600], d_loss: 0.6619, g_loss: 2.1097, D(x): 0.83, D(G(z)): 0.32\n",
      "Epoch [125/200], Step [400/600], d_loss: 0.9605, g_loss: 2.2640, D(x): 0.63, D(G(z)): 0.20\n",
      "Epoch [125/200], Step [600/600], d_loss: 0.9455, g_loss: 2.0946, D(x): 0.69, D(G(z)): 0.29\n",
      "Epoch [150/200], Step [200/600], d_loss: 0.9311, g_loss: 1.8739, D(x): 0.64, D(G(z)): 0.23\n",
      "Epoch [150/200], Step [400/600], d_loss: 0.9263, g_loss: 1.3570, D(x): 0.80, D(G(z)): 0.42\n",
      "Epoch [150/200], Step [600/600], d_loss: 0.9612, g_loss: 1.6224, D(x): 0.70, D(G(z)): 0.33\n",
      "cpu Computing Time: 4642.2502\n",
      "Epoch [175/200], Step [200/600], d_loss: 0.8565, g_loss: 1.4639, D(x): 0.72, D(G(z)): 0.31\n",
      "Epoch [175/200], Step [400/600], d_loss: 1.0316, g_loss: 1.5369, D(x): 0.59, D(G(z)): 0.26\n",
      "Epoch [175/200], Step [600/600], d_loss: 0.9573, g_loss: 1.5581, D(x): 0.71, D(G(z)): 0.34\n",
      "# ================================================================== #\n",
      "#                                      cuda                                         #\n",
      "# ================================================================== #\n",
      "Epoch [0/200], Step [200/600], d_loss: 1.1530, g_loss: 1.6144, D(x): 0.63, D(G(z)): 0.33\n",
      "Epoch [0/200], Step [400/600], d_loss: 1.0565, g_loss: 1.6546, D(x): 0.67, D(G(z)): 0.36\n",
      "Epoch [0/200], Step [600/600], d_loss: 0.9461, g_loss: 1.3749, D(x): 0.75, D(G(z)): 0.38\n",
      "cuda Computing Time: 18.0981\n",
      "Epoch [25/200], Step [200/600], d_loss: 1.0070, g_loss: 1.3883, D(x): 0.70, D(G(z)): 0.38\n",
      "Epoch [25/200], Step [400/600], d_loss: 1.0715, g_loss: 1.3149, D(x): 0.64, D(G(z)): 0.34\n",
      "Epoch [25/200], Step [600/600], d_loss: 0.8502, g_loss: 1.4918, D(x): 0.72, D(G(z)): 0.31\n",
      "Epoch [50/200], Step [200/600], d_loss: 1.0547, g_loss: 1.3349, D(x): 0.67, D(G(z)): 0.35\n",
      "Epoch [50/200], Step [400/600], d_loss: 1.0186, g_loss: 1.4825, D(x): 0.63, D(G(z)): 0.30\n",
      "Epoch [50/200], Step [600/600], d_loss: 1.0355, g_loss: 1.5124, D(x): 0.64, D(G(z)): 0.32\n",
      "cuda Computing Time: 911.4684\n",
      "Epoch [75/200], Step [200/600], d_loss: 0.8986, g_loss: 1.4059, D(x): 0.69, D(G(z)): 0.31\n",
      "Epoch [75/200], Step [400/600], d_loss: 0.9186, g_loss: 1.1889, D(x): 0.69, D(G(z)): 0.33\n",
      "Epoch [75/200], Step [600/600], d_loss: 1.1062, g_loss: 1.0983, D(x): 0.63, D(G(z)): 0.34\n",
      "Epoch [100/200], Step [200/600], d_loss: 1.0875, g_loss: 1.7982, D(x): 0.59, D(G(z)): 0.25\n",
      "Epoch [100/200], Step [400/600], d_loss: 0.9061, g_loss: 1.7063, D(x): 0.65, D(G(z)): 0.25\n",
      "Epoch [100/200], Step [600/600], d_loss: 0.9804, g_loss: 1.3551, D(x): 0.72, D(G(z)): 0.37\n",
      "cuda Computing Time: 1799.7313\n",
      "Epoch [125/200], Step [200/600], d_loss: 0.9775, g_loss: 1.3492, D(x): 0.69, D(G(z)): 0.33\n",
      "Epoch [125/200], Step [400/600], d_loss: 0.9774, g_loss: 1.4223, D(x): 0.67, D(G(z)): 0.33\n",
      "Epoch [125/200], Step [600/600], d_loss: 1.0866, g_loss: 1.3632, D(x): 0.63, D(G(z)): 0.35\n",
      "Epoch [150/200], Step [200/600], d_loss: 0.9625, g_loss: 1.5419, D(x): 0.62, D(G(z)): 0.28\n",
      "Epoch [150/200], Step [400/600], d_loss: 0.9116, g_loss: 1.7989, D(x): 0.69, D(G(z)): 0.30\n",
      "Epoch [150/200], Step [600/600], d_loss: 0.8811, g_loss: 1.2624, D(x): 0.68, D(G(z)): 0.27\n",
      "cuda Computing Time: 2686.4669\n",
      "Epoch [175/200], Step [200/600], d_loss: 1.0118, g_loss: 1.2276, D(x): 0.76, D(G(z)): 0.42\n",
      "Epoch [175/200], Step [400/600], d_loss: 0.9565, g_loss: 1.3847, D(x): 0.72, D(G(z)): 0.37\n",
      "Epoch [175/200], Step [600/600], d_loss: 0.9385, g_loss: 1.7290, D(x): 0.65, D(G(z)): 0.28\n"
     ]
    }
   ],
   "source": [
    "total_step = len(data_loader)\n",
    "log_list_per_25_epochs_cpu = []\n",
    "log_list_per_25_epochs_cuda = []\n",
    "device_types = ['cpu', 'cuda']\n",
    "\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "for device_type in device_types:\n",
    "    device = torch.device(device_type)\n",
    "    D = D.to(device)\n",
    "    G = G.to(device)\n",
    "    \n",
    "    print('# ================================================================== #')\n",
    "    print('#                                      {}                                         #'.format(device_type))\n",
    "    print('# ================================================================== #')\n",
    "    \n",
    "    \n",
    "    # Binary cross entropy loss and optimizer\n",
    "    criterion = nn.BCELoss()\n",
    "    d_optimizer = torch.optim.Adam(D.parameters(), lr=0.0002)\n",
    "    g_optimizer = torch.optim.Adam(G.parameters(), lr=0.0002)\n",
    "\n",
    "    def denorm(x):\n",
    "        out = (x + 1) / 2\n",
    "        return out.clamp(0, 1)\n",
    "\n",
    "\n",
    "    def reset_grad():\n",
    "        d_optimizer.zero_grad()\n",
    "        g_optimizer.zero_grad()\n",
    "    \n",
    "    \n",
    "    starts = time.time()\n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, _) in enumerate(data_loader):\n",
    "            images = images.reshape(batch_size, -1).to(device)\n",
    "\n",
    "            # Create the labels which are later used as input for the BCE loss\n",
    "            real_labels = torch.ones(batch_size, 1).to(device)\n",
    "            fake_labels = torch.zeros(batch_size, 1).to(device)\n",
    "\n",
    "\n",
    "    # ================================================================== #\n",
    "    #                      Train the discriminator                       #\n",
    "    # ================================================================== #\n",
    "\n",
    "            outputs = D(images)\n",
    "            d_loss_real = criterion(outputs, real_labels)\n",
    "            real_score = outputs\n",
    "\n",
    "            # Compute BCELoss using fake images\n",
    "            # First term of the loss is always zero since fake_labels == 0\n",
    "            z = torch.randn(batch_size, latent_size).to(device)\n",
    "            fake_images = G(z)\n",
    "            outputs = D(fake_images)\n",
    "            d_loss_fake = criterion(outputs, fake_labels)\n",
    "            fake_score = outputs     \n",
    "\n",
    "\n",
    "            # Backprop and optimize\n",
    "            d_loss = d_loss_real + d_loss_fake\n",
    "            reset_grad()\n",
    "            d_loss.backward()\n",
    "            d_optimizer.step()\n",
    "\n",
    "\n",
    "            # ================================================================== #\n",
    "            #                        Train the generator                         #\n",
    "            # ================================================================== #\n",
    "\n",
    "            # Compute loss with fake images\n",
    "            z = torch.randn(batch_size, latent_size).to(device)\n",
    "            fake_images = G(z)\n",
    "            outputs = D(fake_images)\n",
    "\n",
    "            # We train G to maximize log(D(G(z)) instead of minimizing log(1-D(G(z)))\n",
    "            # For the reason, see the last paragraph of section 3. https://arxiv.org/pdf/1406.2661.pdf\n",
    "            g_loss = criterion(outputs, real_labels)\n",
    "\n",
    "            # Backprop and optimize\n",
    "            reset_grad()\n",
    "            g_loss.backward()\n",
    "            g_optimizer.step()\n",
    "\n",
    "            if epoch %25 ==0 and (i+1) % 200 == 0:\n",
    "                print('Epoch [{}/{}], Step [{}/{}], d_loss: {:.4f}, g_loss: {:.4f}, D(x): {:.2f}, D(G(z)): {:.2f}' \n",
    "                      .format(epoch, num_epochs, i+1, total_step, d_loss.item(), g_loss.item(), \n",
    "                              real_score.mean().item(), fake_score.mean().item()))\n",
    "                              \n",
    "            if device_type =='cpu':\n",
    "                if epoch % 25 == 0 and (i+1) % 600==0:\n",
    "                    take_time = time.time() - starts\n",
    "                    log_list_per_25_epochs_cpu.append(take_time)\n",
    "            \n",
    "            else:\n",
    "                if epoch % 25 == 0 and (i+1) % 600==0:\n",
    "                    take_time = time.time() - starts\n",
    "                    log_list_per_25_epochs_cuda.append(take_time)\n",
    "\n",
    "            if epoch % 50 ==0 and (i+1) % 600 ==0:\n",
    "                take_time = time.time() - starts\n",
    "                print('{} Computing Time: {:.4f}'.format(device_type, take_time))\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[26.589967489242554,\n",
       " 759.5416057109833,\n",
       " 1548.730007648468,\n",
       " 2314.4079563617706,\n",
       " 3078.567747116089,\n",
       " 3856.698341846466,\n",
       " 4642.250211954117,\n",
       " 5438.164389133453]"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_list_per_25_epochs_cpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[18.09806537628174,\n",
       " 468.9906985759735,\n",
       " 911.4684159755707,\n",
       " 1356.9603612422943,\n",
       " 1799.7313268184662,\n",
       " 2243.6638650894165,\n",
       " 2686.466948032379,\n",
       " 3138.6666300296783]"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_list_per_25_epochs_cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(data={'Epochs': ['1 Time', '25 Times','50 Times', '75 Times','100 Times','125 Times','150 Times','175 Times'],\n",
    "    'local CPU':[26.589967489242554,  759.5416057109833,\n",
    "                                     1548.730007648468,  2314.4079563617706,3078.567747116089,\n",
    "                                     3856.698341846466, 4642.250211954117, 5438.164389133453],\n",
    "                       'local GPU':[18.09806537628174, 468.9906985759735, 911.4684159755707, 1356.9603612422943, \n",
    "                                    1799.7313268184662, 2243.6638650894165, 2686.466948032379, 3138.6666300296783],\n",
    "                       'Nipa CPU':[75.14369893074036,1666.85045003891, 2370.6793422698975, 2891.0353157520294, \n",
    "                                   3403.7471404075623, 3919.007220506668, 4515.387395143509, 5201.6457941532135],\n",
    "                       'Nipa GPU': [12.760392427444458, 348.51575088500977, 675.844676733017, 1009.0489814281464, \n",
    "                                    1342.2661945819855, 1675.650508403778, 2006.4203536510468, 2340.548830986023]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df.round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Epochs</th>\n",
       "      <th>local CPU</th>\n",
       "      <th>local GPU</th>\n",
       "      <th>Nipa CPU</th>\n",
       "      <th>Nipa GPU</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1 Time</td>\n",
       "      <td>26.59</td>\n",
       "      <td>18.10</td>\n",
       "      <td>75.14</td>\n",
       "      <td>12.76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25 Times</td>\n",
       "      <td>759.54</td>\n",
       "      <td>468.99</td>\n",
       "      <td>1666.85</td>\n",
       "      <td>348.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>50 Times</td>\n",
       "      <td>1548.73</td>\n",
       "      <td>911.47</td>\n",
       "      <td>2370.68</td>\n",
       "      <td>675.84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75 Times</td>\n",
       "      <td>2314.41</td>\n",
       "      <td>1356.96</td>\n",
       "      <td>2891.04</td>\n",
       "      <td>1009.05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>100 Times</td>\n",
       "      <td>3078.57</td>\n",
       "      <td>1799.73</td>\n",
       "      <td>3403.75</td>\n",
       "      <td>1342.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>125 Times</td>\n",
       "      <td>3856.70</td>\n",
       "      <td>2243.66</td>\n",
       "      <td>3919.01</td>\n",
       "      <td>1675.65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>150 Times</td>\n",
       "      <td>4642.25</td>\n",
       "      <td>2686.47</td>\n",
       "      <td>4515.39</td>\n",
       "      <td>2006.42</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>175 Times</td>\n",
       "      <td>5438.16</td>\n",
       "      <td>3138.67</td>\n",
       "      <td>5201.65</td>\n",
       "      <td>2340.55</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Epochs  local CPU  local GPU  Nipa CPU  Nipa GPU\n",
       "0     1 Time      26.59      18.10     75.14     12.76\n",
       "1   25 Times     759.54     468.99   1666.85    348.52\n",
       "2   50 Times    1548.73     911.47   2370.68    675.84\n",
       "3   75 Times    2314.41    1356.96   2891.04   1009.05\n",
       "4  100 Times    3078.57    1799.73   3403.75   1342.27\n",
       "5  125 Times    3856.70    2243.66   3919.01   1675.65\n",
       "6  150 Times    4642.25    2686.47   4515.39   2006.42\n",
       "7  175 Times    5438.16    3138.67   5201.65   2340.55"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
